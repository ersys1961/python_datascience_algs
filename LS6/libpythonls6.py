# -*- coding: utf-8 -*-
"""LibPythonLS6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1B8XbmbJCSLV8YIog8HhgOQasuv_wLBar
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import warnings

warnings.filterwarnings('ignore')

from sklearn.datasets import load_boston
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score
from sklearn.metrics import mean_absolute_error
from matplotlib import pyplot as plt
# %matplotlib inline

# Задание 1   Стандартизации признаков нет в задании?
boston = load_boston()
#print(boston.keys())

data = boston["data"]
feature_names = boston["feature_names"]
X = pd.DataFrame(data, columns=feature_names)
target = boston["target"]
Y = pd.DataFrame(target, columns=["price"])
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)

lr = LinearRegression()
lr.fit(X_train, Y_train)

Y_pred = lr.predict(X_test)
print(mean_absolute_error(Y_pred, Y_test["price"]))
print(r2_score(Y_pred, Y_test["price"]))

# Задание 2  Random Forest работает лучше для заданного датасета
rf = RandomForestRegressor(max_depth=12, n_estimators = 1000)
rf.fit(X_train, Y_train.values[:, 0]) 

Y_pred = rf.predict(X_test)
print(mean_absolute_error(Y_pred, Y_test["price"]))
print(r2_score(Y_pred, Y_test["price"]))

# Задание 3   Наибольшая важность: RM  и LSTAT
print(rf.feature_importances_)
print(sum(rf.feature_importances_))
sorted_idx = rf.feature_importances_.argsort()
plt.barh(boston.feature_names[sorted_idx], rf.feature_importances_[sorted_idx])
plt.xlabel("Random Forest Feature Importance")

# Commented out IPython magic to ensure Python compatibility.
# Задание 4
import numpy as np
import pandas as pd
from scipy.stats import mode
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from matplotlib import pyplot as plt
# %matplotlib inline

import warnings
warnings.filterwarnings('ignore')

from google.colab import drive
drive.mount('/content/gdrive')

DATASET_PATH = 'gdrive/My Drive/Colab Notebooks/creditcard.csv'

df = pd.read_csv(DATASET_PATH, sep=',')
df['Class'].value_counts(normalize = True)
df.info()
pd.options.display.max_columns = 100
df.head(10)

Y=df["Class"]
X=df.drop(columns = ['Class'])
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=100,  stratify=Y)
X_train.shape, Y_train.shape, X_test.shape, Y_test.shape
parameters = {
    'n_estimators': [10, 15],
    'max_features': np.arange(3, 5),
    'max_depth': np.arange(4, 7),
}
clf = GridSearchCV(
    estimator=RandomForestClassifier(),
    param_grid=parameters,
    scoring='roc_auc',
    cv=3,
)
clf.fit(X_train, Y_train)

clf.best_params_
clf.predict_proba(X_test)
y_pred_proba =  clf.predict_proba(X_test)[:,1]
y_pred_proba
from sklearn.metrics import roc_auc_score
roc_auc_score(Y_test, y_pred_proba)