{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LibPythonLS6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiixDPZQEf3Z"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iO52LKr7Ez7G",
        "outputId": "526fdcaa-5100-45cc-acf7-bd8116ce1fef"
      },
      "source": [
        "# Задание 1   Стандартизации признаков нет в задании?\n",
        "boston = load_boston()\n",
        "#print(boston.keys())\n",
        "\n",
        "data = boston[\"data\"]\n",
        "feature_names = boston[\"feature_names\"]\n",
        "X = pd.DataFrame(data, columns=feature_names)\n",
        "target = boston[\"target\"]\n",
        "Y = pd.DataFrame(target, columns=[\"price\"])\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n",
        "\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = lr.predict(X_test)\n",
        "print(mean_absolute_error(Y_pred, Y_test[\"price\"]))\n",
        "print(r2_score(Y_pred, Y_test[\"price\"]))\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.0609395954370897\n",
            "0.658685620226924\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eC5MBsERYZa",
        "outputId": "0b894201-6174-45c1-f8dd-bc9ef61d801a"
      },
      "source": [
        "# Задание 2  Random Forest работает лучше для заданного датасета\n",
        "rf = RandomForestRegressor(max_depth=12, n_estimators = 1000)\n",
        "rf.fit(X_train, Y_train.values[:, 0]) \n",
        "\n",
        "Y_pred = rf.predict(X_test)\n",
        "print(mean_absolute_error(Y_pred, Y_test[\"price\"]))\n",
        "print(r2_score(Y_pred, Y_test[\"price\"]))\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1189846796620855\n",
            "0.8285187959754547\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "gaCvh4ejJSxF",
        "outputId": "4ecf3451-3af2-4bb2-94f8-3770d8a93508"
      },
      "source": [
        "# Задание 3   Наибольшая важность: RM  и LSTAT\n",
        "print(rf.feature_importances_)\n",
        "print(sum(rf.feature_importances_))\n",
        "sorted_idx = rf.feature_importances_.argsort()\n",
        "plt.barh(boston.feature_names[sorted_idx], rf.feature_importances_[sorted_idx])\n",
        "plt.xlabel(\"Random Forest Feature Importance\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.03894135 0.0016253  0.0066774  0.00098499 0.01228372 0.44074452\n",
            " 0.01483351 0.05857725 0.00477552 0.01215675 0.01734472 0.01271289\n",
            " 0.37834208]\n",
            "1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Random Forest Feature Importance')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NB3RCuDlP47p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6217f78c-214d-4607-933a-fbe549157b8d"
      },
      "source": [
        "# Задание 4\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import mode\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "DATASET_PATH = 'gdrive/My Drive/Colab Notebooks/creditcard.csv'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Gt37J7OZOt-L",
        "outputId": "63b905b3-b49d-4fcc-9d42-2e9cb1902ae7"
      },
      "source": [
        "df = pd.read_csv(DATASET_PATH, sep=',')\n",
        "df['Class'].value_counts(normalize = True)\n",
        "df.info()\n",
        "pd.options.display.max_columns = 100\n",
        "df.head(10)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 284807 entries, 0 to 284806\n",
            "Data columns (total 31 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   Time    284807 non-null  float64\n",
            " 1   V1      284807 non-null  float64\n",
            " 2   V2      284807 non-null  float64\n",
            " 3   V3      284807 non-null  float64\n",
            " 4   V4      284807 non-null  float64\n",
            " 5   V5      284807 non-null  float64\n",
            " 6   V6      284807 non-null  float64\n",
            " 7   V7      284807 non-null  float64\n",
            " 8   V8      284807 non-null  float64\n",
            " 9   V9      284807 non-null  float64\n",
            " 10  V10     284807 non-null  float64\n",
            " 11  V11     284807 non-null  float64\n",
            " 12  V12     284807 non-null  float64\n",
            " 13  V13     284807 non-null  float64\n",
            " 14  V14     284807 non-null  float64\n",
            " 15  V15     284807 non-null  float64\n",
            " 16  V16     284807 non-null  float64\n",
            " 17  V17     284807 non-null  float64\n",
            " 18  V18     284807 non-null  float64\n",
            " 19  V19     284807 non-null  float64\n",
            " 20  V20     284807 non-null  float64\n",
            " 21  V21     284807 non-null  float64\n",
            " 22  V22     284807 non-null  float64\n",
            " 23  V23     284807 non-null  float64\n",
            " 24  V24     284807 non-null  float64\n",
            " 25  V25     284807 non-null  float64\n",
            " 26  V26     284807 non-null  float64\n",
            " 27  V27     284807 non-null  float64\n",
            " 28  V28     284807 non-null  float64\n",
            " 29  Amount  284807 non-null  float64\n",
            " 30  Class   284807 non-null  int64  \n",
            "dtypes: float64(30), int64(1)\n",
            "memory usage: 67.4 MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.425966</td>\n",
              "      <td>0.960523</td>\n",
              "      <td>1.141109</td>\n",
              "      <td>-0.168252</td>\n",
              "      <td>0.420987</td>\n",
              "      <td>-0.029728</td>\n",
              "      <td>0.476201</td>\n",
              "      <td>0.260314</td>\n",
              "      <td>-0.568671</td>\n",
              "      <td>-0.371407</td>\n",
              "      <td>1.341262</td>\n",
              "      <td>0.359894</td>\n",
              "      <td>-0.358091</td>\n",
              "      <td>-0.137134</td>\n",
              "      <td>0.517617</td>\n",
              "      <td>0.401726</td>\n",
              "      <td>-0.058133</td>\n",
              "      <td>0.068653</td>\n",
              "      <td>-0.033194</td>\n",
              "      <td>0.084968</td>\n",
              "      <td>-0.208254</td>\n",
              "      <td>-0.559825</td>\n",
              "      <td>-0.026398</td>\n",
              "      <td>-0.371427</td>\n",
              "      <td>-0.232794</td>\n",
              "      <td>0.105915</td>\n",
              "      <td>0.253844</td>\n",
              "      <td>0.081080</td>\n",
              "      <td>3.67</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4.0</td>\n",
              "      <td>1.229658</td>\n",
              "      <td>0.141004</td>\n",
              "      <td>0.045371</td>\n",
              "      <td>1.202613</td>\n",
              "      <td>0.191881</td>\n",
              "      <td>0.272708</td>\n",
              "      <td>-0.005159</td>\n",
              "      <td>0.081213</td>\n",
              "      <td>0.464960</td>\n",
              "      <td>-0.099254</td>\n",
              "      <td>-1.416907</td>\n",
              "      <td>-0.153826</td>\n",
              "      <td>-0.751063</td>\n",
              "      <td>0.167372</td>\n",
              "      <td>0.050144</td>\n",
              "      <td>-0.443587</td>\n",
              "      <td>0.002821</td>\n",
              "      <td>-0.611987</td>\n",
              "      <td>-0.045575</td>\n",
              "      <td>-0.219633</td>\n",
              "      <td>-0.167716</td>\n",
              "      <td>-0.270710</td>\n",
              "      <td>-0.154104</td>\n",
              "      <td>-0.780055</td>\n",
              "      <td>0.750137</td>\n",
              "      <td>-0.257237</td>\n",
              "      <td>0.034507</td>\n",
              "      <td>0.005168</td>\n",
              "      <td>4.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7.0</td>\n",
              "      <td>-0.644269</td>\n",
              "      <td>1.417964</td>\n",
              "      <td>1.074380</td>\n",
              "      <td>-0.492199</td>\n",
              "      <td>0.948934</td>\n",
              "      <td>0.428118</td>\n",
              "      <td>1.120631</td>\n",
              "      <td>-3.807864</td>\n",
              "      <td>0.615375</td>\n",
              "      <td>1.249376</td>\n",
              "      <td>-0.619468</td>\n",
              "      <td>0.291474</td>\n",
              "      <td>1.757964</td>\n",
              "      <td>-1.323865</td>\n",
              "      <td>0.686133</td>\n",
              "      <td>-0.076127</td>\n",
              "      <td>-1.222127</td>\n",
              "      <td>-0.358222</td>\n",
              "      <td>0.324505</td>\n",
              "      <td>-0.156742</td>\n",
              "      <td>1.943465</td>\n",
              "      <td>-1.015455</td>\n",
              "      <td>0.057504</td>\n",
              "      <td>-0.649709</td>\n",
              "      <td>-0.415267</td>\n",
              "      <td>-0.051634</td>\n",
              "      <td>-1.206921</td>\n",
              "      <td>-1.085339</td>\n",
              "      <td>40.80</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7.0</td>\n",
              "      <td>-0.894286</td>\n",
              "      <td>0.286157</td>\n",
              "      <td>-0.113192</td>\n",
              "      <td>-0.271526</td>\n",
              "      <td>2.669599</td>\n",
              "      <td>3.721818</td>\n",
              "      <td>0.370145</td>\n",
              "      <td>0.851084</td>\n",
              "      <td>-0.392048</td>\n",
              "      <td>-0.410430</td>\n",
              "      <td>-0.705117</td>\n",
              "      <td>-0.110452</td>\n",
              "      <td>-0.286254</td>\n",
              "      <td>0.074355</td>\n",
              "      <td>-0.328783</td>\n",
              "      <td>-0.210077</td>\n",
              "      <td>-0.499768</td>\n",
              "      <td>0.118765</td>\n",
              "      <td>0.570328</td>\n",
              "      <td>0.052736</td>\n",
              "      <td>-0.073425</td>\n",
              "      <td>-0.268092</td>\n",
              "      <td>-0.204233</td>\n",
              "      <td>1.011592</td>\n",
              "      <td>0.373205</td>\n",
              "      <td>-0.384157</td>\n",
              "      <td>0.011747</td>\n",
              "      <td>0.142404</td>\n",
              "      <td>93.20</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9.0</td>\n",
              "      <td>-0.338262</td>\n",
              "      <td>1.119593</td>\n",
              "      <td>1.044367</td>\n",
              "      <td>-0.222187</td>\n",
              "      <td>0.499361</td>\n",
              "      <td>-0.246761</td>\n",
              "      <td>0.651583</td>\n",
              "      <td>0.069539</td>\n",
              "      <td>-0.736727</td>\n",
              "      <td>-0.366846</td>\n",
              "      <td>1.017614</td>\n",
              "      <td>0.836390</td>\n",
              "      <td>1.006844</td>\n",
              "      <td>-0.443523</td>\n",
              "      <td>0.150219</td>\n",
              "      <td>0.739453</td>\n",
              "      <td>-0.540980</td>\n",
              "      <td>0.476677</td>\n",
              "      <td>0.451773</td>\n",
              "      <td>0.203711</td>\n",
              "      <td>-0.246914</td>\n",
              "      <td>-0.633753</td>\n",
              "      <td>-0.120794</td>\n",
              "      <td>-0.385050</td>\n",
              "      <td>-0.069733</td>\n",
              "      <td>0.094199</td>\n",
              "      <td>0.246219</td>\n",
              "      <td>0.083076</td>\n",
              "      <td>3.68</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
              "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
              "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
              "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
              "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
              "5   2.0 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728  0.476201   \n",
              "6   4.0  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708 -0.005159   \n",
              "7   7.0 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118  1.120631   \n",
              "8   7.0 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818  0.370145   \n",
              "9   9.0 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761  0.651583   \n",
              "\n",
              "         V8        V9       V10       V11       V12       V13       V14  \\\n",
              "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
              "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
              "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
              "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
              "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
              "5  0.260314 -0.568671 -0.371407  1.341262  0.359894 -0.358091 -0.137134   \n",
              "6  0.081213  0.464960 -0.099254 -1.416907 -0.153826 -0.751063  0.167372   \n",
              "7 -3.807864  0.615375  1.249376 -0.619468  0.291474  1.757964 -1.323865   \n",
              "8  0.851084 -0.392048 -0.410430 -0.705117 -0.110452 -0.286254  0.074355   \n",
              "9  0.069539 -0.736727 -0.366846  1.017614  0.836390  1.006844 -0.443523   \n",
              "\n",
              "        V15       V16       V17       V18       V19       V20       V21  \\\n",
              "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
              "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
              "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
              "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
              "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
              "5  0.517617  0.401726 -0.058133  0.068653 -0.033194  0.084968 -0.208254   \n",
              "6  0.050144 -0.443587  0.002821 -0.611987 -0.045575 -0.219633 -0.167716   \n",
              "7  0.686133 -0.076127 -1.222127 -0.358222  0.324505 -0.156742  1.943465   \n",
              "8 -0.328783 -0.210077 -0.499768  0.118765  0.570328  0.052736 -0.073425   \n",
              "9  0.150219  0.739453 -0.540980  0.476677  0.451773  0.203711 -0.246914   \n",
              "\n",
              "        V22       V23       V24       V25       V26       V27       V28  \\\n",
              "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
              "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
              "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
              "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
              "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
              "5 -0.559825 -0.026398 -0.371427 -0.232794  0.105915  0.253844  0.081080   \n",
              "6 -0.270710 -0.154104 -0.780055  0.750137 -0.257237  0.034507  0.005168   \n",
              "7 -1.015455  0.057504 -0.649709 -0.415267 -0.051634 -1.206921 -1.085339   \n",
              "8 -0.268092 -0.204233  1.011592  0.373205 -0.384157  0.011747  0.142404   \n",
              "9 -0.633753 -0.120794 -0.385050 -0.069733  0.094199  0.246219  0.083076   \n",
              "\n",
              "   Amount  Class  \n",
              "0  149.62      0  \n",
              "1    2.69      0  \n",
              "2  378.66      0  \n",
              "3  123.50      0  \n",
              "4   69.99      0  \n",
              "5    3.67      0  \n",
              "6    4.99      0  \n",
              "7   40.80      0  \n",
              "8   93.20      0  \n",
              "9    3.68      0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igLkQuZ6fIth",
        "outputId": "39a7040b-0834-4d20-a0e7-9190d4ea93bd"
      },
      "source": [
        "Y=df[\"Class\"]\n",
        "X=df.drop(columns = ['Class'])\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=100,  stratify=Y)\n",
        "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape\n",
        "parameters = {\n",
        "    'n_estimators': [10, 15],\n",
        "    'max_features': np.arange(3, 5),\n",
        "    'max_depth': np.arange(4, 7),\n",
        "}\n",
        "clf = GridSearchCV(\n",
        "    estimator=RandomForestClassifier(),\n",
        "    param_grid=parameters,\n",
        "    scoring='roc_auc',\n",
        "    cv=3,\n",
        ")\n",
        "clf.fit(X_train, Y_train)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score=nan,\n",
              "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                              class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features='auto',\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              max_samples=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              n_estimators=100, n_jobs=None,\n",
              "                                              oob_score=False,\n",
              "                                              random_state=None, verbose=0,\n",
              "                                              warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'max_depth': array([4, 5, 6]),\n",
              "                         'max_features': array([3, 4]),\n",
              "                         'n_estimators': [10, 15]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='roc_auc', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pL8wVEd9lbF2",
        "outputId": "ae2dcfaa-9ac7-4fd0-beba-25c128aaa018"
      },
      "source": [
        "clf.best_params_\n",
        "clf.predict_proba(X_test)\n",
        "y_pred_proba =  clf.predict_proba(X_test)[:,1]\n",
        "y_pred_proba\n",
        "from sklearn.metrics import roc_auc_score\n",
        "roc_auc_score(Y_test, y_pred_proba)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9575829038488046"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    }
  ]
}